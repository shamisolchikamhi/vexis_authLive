{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import io\n",
    "\n",
    "from api_request_funtions import ApiGet\n",
    "from bq_transfers import BqDataTransfers \n",
    "# from main import fetch_and_save\n",
    "import json"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "thrivecart_get = ApiGet(http='thrivecart.com', api_key='TZ5TJYBR-FDB85IBI-0RFTB00N-VQ7ZFY2S')\n",
    "thrivecart_save = BqDataTransfers(gcp_project_id= 'arboreal-cat-451816-n0', bq_data_set = 'thrive_cart')\n",
    "bq_client = thrivecart_save.get_bq_client(\"/Users/shami/Library/Mobile Documents/com~apple~CloudDocs/Personal Projects/vexis/vexis_bq_writter.json\")\n",
    "\n",
    "# split products"
   ],
   "id": "ae3af2ad50edf3ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T18:29:56.067394Z",
     "start_time": "2025-03-10T18:29:55.195452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define your API URL and credentials\n",
    "api_url = \"https://api.kajabi.com/v1/payments/transactions\"  # Replace with the correct API endpoint\n",
    "api_token = 'xxxxxxxx'\n",
    "api_secret = 'xxxxxxxxxxxxx' # Replace with your API secret if required\n",
    "\n",
    "# Set the parameters for the query\n",
    "params = {\n",
    "    \"page\": 1,\n",
    "    \"sort\": \"date\",\n",
    "    \"direction\": \"desc\",\n",
    "    \"in_the_last\": \"30_days\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.get(api_url, headers=headers, params=params)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    print(json.dumps(data, indent=2))  # Pretty print the JSON data\n",
    "else:\n",
    "    # Handle errors\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.text)\n"
   ],
   "id": "620de480dd75ac18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 404\n",
      "{\"message\":\"Not Found\"}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T16:47:41.435534Z",
     "start_time": "2025-03-11T16:47:39.759870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "token_url = 'https://kajabi.com/oauth/token'\n",
    "\n",
    "data = {\n",
    "  \"client_id\": \"xxxxxxxxxxx\",\n",
    "  \"client_secret\": \"xxxxxxxxxxx\",\n",
    "  \"grant_type\": \"client_credentials\"\n",
    "}\n",
    "\n",
    "\n",
    "response = requests.post(token_url, data=data)\n",
    "access_token = response.json()['access_token']"
   ],
   "id": "b5037432fa58c26",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shami/personal_projects/vexis_authLive/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[0;32m~/personal_projects/vexis_authLive/.venv/lib/python3.9/site-packages/requests/models.py:974\u001B[0m, in \u001B[0;36mResponse.json\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    973\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 974\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcomplexjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    975\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m JSONDecodeError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    976\u001B[0m     \u001B[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001B[39;00m\n\u001B[1;32m    977\u001B[0m     \u001B[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/__init__.py:346\u001B[0m, in \u001B[0;36mloads\u001B[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[1;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    344\u001B[0m         parse_int \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m parse_float \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    345\u001B[0m         parse_constant \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_pairs_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kw):\n\u001B[0;32m--> 346\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_decoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/decoder.py:337\u001B[0m, in \u001B[0;36mJSONDecoder.decode\u001B[0;34m(self, s, _w)\u001B[0m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03mcontaining a JSON document).\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m--> 337\u001B[0m obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_w\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    338\u001B[0m end \u001B[38;5;241m=\u001B[39m _w(s, end)\u001B[38;5;241m.\u001B[39mend()\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/decoder.py:355\u001B[0m, in \u001B[0;36mJSONDecoder.raw_decode\u001B[0;34m(self, s, idx)\u001B[0m\n\u001B[1;32m    354\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m--> 355\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m JSONDecodeError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpecting value\u001B[39m\u001B[38;5;124m\"\u001B[39m, s, err\u001B[38;5;241m.\u001B[39mvalue) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    356\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj, end\n",
      "\u001B[0;31mJSONDecodeError\u001B[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 15\u001B[0m\n\u001B[1;32m      7\u001B[0m data \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      8\u001B[0m   \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclient_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mB7gSbosJ5ko3EWmZgnSQJzAg\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      9\u001B[0m   \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclient_secret\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mysVNEgmz2FC7KiztmUAV4SMx\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     10\u001B[0m   \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgrant_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclient_credentials\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     11\u001B[0m }\n\u001B[1;32m     14\u001B[0m response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mpost(token_url, data\u001B[38;5;241m=\u001B[39mdata)\n\u001B[0;32m---> 15\u001B[0m access_token \u001B[38;5;241m=\u001B[39m \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccess_token\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m~/personal_projects/vexis_authLive/.venv/lib/python3.9/site-packages/requests/models.py:978\u001B[0m, in \u001B[0;36mResponse.json\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    974\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m complexjson\u001B[38;5;241m.\u001B[39mloads(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    975\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m JSONDecodeError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    976\u001B[0m     \u001B[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001B[39;00m\n\u001B[1;32m    977\u001B[0m     \u001B[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001B[39;00m\n\u001B[0;32m--> 978\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RequestsJSONDecodeError(e\u001B[38;5;241m.\u001B[39mmsg, e\u001B[38;5;241m.\u001B[39mdoc, e\u001B[38;5;241m.\u001B[39mpos)\n",
      "\u001B[0;31mJSONDecodeError\u001B[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-10T19:26:10.560290Z",
     "start_time": "2025-03-10T19:26:09.390042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://app.kajabi.com/api/v1/me\"\n",
    "data = {\n",
    "    \"username\": \"authenticliving@vexis.co.uk\",\n",
    "    \"password\": \"Authenticliving@3141\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=data)\n",
    "\n",
    "# Print the response (access_token and refresh_token)\n",
    "print(response.json())\n"
   ],
   "id": "9f1ca35370d743bd",
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[0;32m~/personal_projects/vexis_authLive/.venv/lib/python3.9/site-packages/requests/models.py:974\u001B[0m, in \u001B[0;36mResponse.json\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    973\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 974\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcomplexjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloads\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    975\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m JSONDecodeError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    976\u001B[0m     \u001B[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001B[39;00m\n\u001B[1;32m    977\u001B[0m     \u001B[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/__init__.py:346\u001B[0m, in \u001B[0;36mloads\u001B[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001B[0m\n\u001B[1;32m    343\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    344\u001B[0m         parse_int \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m parse_float \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    345\u001B[0m         parse_constant \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m object_pairs_hook \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m kw):\n\u001B[0;32m--> 346\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_decoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/decoder.py:337\u001B[0m, in \u001B[0;36mJSONDecoder.decode\u001B[0;34m(self, s, _w)\u001B[0m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001B[39;00m\n\u001B[1;32m    334\u001B[0m \u001B[38;5;124;03mcontaining a JSON document).\u001B[39;00m\n\u001B[1;32m    335\u001B[0m \n\u001B[1;32m    336\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m--> 337\u001B[0m obj, end \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw_decode\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_w\u001B[49m\u001B[43m(\u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mend\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    338\u001B[0m end \u001B[38;5;241m=\u001B[39m _w(s, end)\u001B[38;5;241m.\u001B[39mend()\n",
      "File \u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/json/decoder.py:355\u001B[0m, in \u001B[0;36mJSONDecoder.raw_decode\u001B[0;34m(self, s, idx)\u001B[0m\n\u001B[1;32m    354\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m--> 355\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m JSONDecodeError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpecting value\u001B[39m\u001B[38;5;124m\"\u001B[39m, s, err\u001B[38;5;241m.\u001B[39mvalue) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    356\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m obj, end\n",
      "\u001B[0;31mJSONDecodeError\u001B[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mJSONDecodeError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[35], line 12\u001B[0m\n\u001B[1;32m      9\u001B[0m response \u001B[38;5;241m=\u001B[39m requests\u001B[38;5;241m.\u001B[39mpost(url, json\u001B[38;5;241m=\u001B[39mdata)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Print the response (access_token and refresh_token)\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjson\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/personal_projects/vexis_authLive/.venv/lib/python3.9/site-packages/requests/models.py:978\u001B[0m, in \u001B[0;36mResponse.json\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    974\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m complexjson\u001B[38;5;241m.\u001B[39mloads(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    975\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m JSONDecodeError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    976\u001B[0m     \u001B[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001B[39;00m\n\u001B[1;32m    977\u001B[0m     \u001B[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001B[39;00m\n\u001B[0;32m--> 978\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RequestsJSONDecodeError(e\u001B[38;5;241m.\u001B[39mmsg, e\u001B[38;5;241m.\u001B[39mdoc, e\u001B[38;5;241m.\u001B[39mpos)\n",
      "\u001B[0;31mJSONDecodeError\u001B[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T15:32:17.105858Z",
     "start_time": "2025-06-16T15:32:16.172629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from api_request_funtions import ApiGet\n",
    "from api_request_funtions import ApiGetRequest\n",
    "from bq_transfers import BqDataTransfers\n",
    "from  bq_transfers import pub_sub_message_publisher\n",
    "import io\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import HTTPError\n",
    "import pandas as pd\n",
    "import json\n",
    "from urllib.parse import urlencode"
   ],
   "id": "6bb7055f379ee13f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shami/personal_projects/vexis_authLive/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T15:32:34.462152Z",
     "start_time": "2025-06-16T15:32:34.434320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "project_id = 'arboreal-cat-451816-n0'\n",
    "headers = {\n",
    "    'API-Key': 'API_c1c14fe7384d5050491b9d0c401184bd6facb348ccc8c59d2a53cdcec9c14332'\n",
    "}\n",
    "hyros_save = BqDataTransfers(gcp_project_id=project_id, bq_data_set='hyros')\n",
    "bq_client = hyros_save.get_bq_client(\n",
    "    \"/Users/shami/Library/Mobile Documents/com~apple~CloudDocs/Personal Projects/vexis/vexis_bq_writter.json\"\n",
    ")\n",
    "\n",
    "def _process_and_save_df(df: pd.DataFrame, table_id: str, date, page_id):\n",
    "    \"\"\"\n",
    "    Aligns and uploads the DataFrame to BigQuery.\n",
    "    Adds missing columns to table or DataFrame to ensure schema match.\n",
    "    \"\"\"\n",
    "    print(f\"🔄 Processing data for {table_id} | Date: {date} | Page: {page_id}\")\n",
    "    try:\n",
    "        df['creationDate'] = pd.to_datetime(df['creationDate']).dt.tz_convert('UTC')\n",
    "    except:\n",
    "        df['creationDate'] = pd.to_datetime(df['creationDate'], unit='ms', utc=True)\n",
    "    try:\n",
    "        df.columns = df.columns.str.replace(r'\\.', '_', regex=True)\n",
    "        align_and_upload_to_bq(df, f\"hyros.{table_id}\", project_id=hyros_save.gcp_project_id)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process and upload data: {e}\")\n",
    "\n",
    "\n",
    "def align_and_upload_to_bq(df, table_id, project_id):\n",
    "    # Flatten list-like columns (arrays) into strings to prevent pyarrow issues\n",
    "    for col in df.columns:\n",
    "        if df[col].apply(lambda x: isinstance(x, list)).any():\n",
    "            print(f\"⚠️ Flattening list column: {col}\")\n",
    "            df[col] = df[col].apply(lambda x: ','.join(map(str, x)) if isinstance(x, list) else x)\n",
    "\n",
    "    # Get current table schema\n",
    "    table = bq_client.get_table(table_id)\n",
    "    bq_schema = table.schema\n",
    "\n",
    "    # Create sets for comparison\n",
    "    df_columns = set(df.columns)\n",
    "    bq_columns = set(field.name for field in bq_schema)\n",
    "\n",
    "    # Columns in df but not in BigQuery table (need to add to BQ table)\n",
    "    columns_to_add_to_bq = df_columns - bq_columns\n",
    "\n",
    "    for col in columns_to_add_to_bq:\n",
    "        dtype = df[col].dropna().infer_objects().dtype\n",
    "        if pd.api.types.is_string_dtype(dtype):\n",
    "            field_type = \"STRING\"\n",
    "        elif pd.api.types.is_bool_dtype(dtype):\n",
    "            field_type = \"BOOLEAN\"\n",
    "        elif pd.api.types.is_integer_dtype(dtype):\n",
    "            field_type = \"INT64\"\n",
    "        elif pd.api.types.is_float_dtype(dtype):\n",
    "            field_type = \"FLOAT64\"\n",
    "        elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "            field_type = \"TIMESTAMP\"\n",
    "        else:\n",
    "            field_type = \"STRING\"  # fallback for complex types\n",
    "\n",
    "        query = f\"\"\"\n",
    "        ALTER TABLE `{table_id}`\n",
    "        ADD COLUMN `{col}` {field_type};\n",
    "        \"\"\"\n",
    "        bq_client.query(query).result()\n",
    "        print(f\"➕ Added column `{col}` ({field_type}) to {table_id}\")\n",
    "\n",
    "    # Columns in BQ table but not in df (need to add as nulls)\n",
    "    columns_to_add_to_df = bq_columns - df_columns\n",
    "    for col in columns_to_add_to_df:\n",
    "        dtype = next(field.field_type for field in bq_schema if field.name == col)\n",
    "        if dtype == \"STRING\":\n",
    "            df[col] = None\n",
    "        elif dtype in [\"INT64\", \"FLOAT64\", \"BOOLEAN\"]:\n",
    "            df[col] = np.nan\n",
    "        elif dtype == \"TIMESTAMP\":\n",
    "            df[col] = pd.NaT\n",
    "        else:\n",
    "            df[col] = None  # fallback\n",
    "\n",
    "    # Reorder columns to match BQ schema\n",
    "    df = df[[field.name for field in bq_schema]]\n",
    "\n",
    "    # Upload to BigQuery\n",
    "    job = bq_client.load_table_from_dataframe(df, table_id)\n",
    "    job.result()  # Wait for completion\n",
    "    print(f\"✅ Uploaded {len(df)} rows to {table_id}\")\n",
    "\n",
    "def fetch_and_store_hyros_data(\n",
    "    endpoint: str,\n",
    "    destination_table: str,\n",
    "    start_date: str = None,\n",
    "    end_date: str = None,\n",
    "    use_date_and_pagination: bool = True,\n",
    "):\n",
    "    resume_table = f\"{destination_table}_resume_state\"\n",
    "    dataset_id = hyros_save.bq_data_set\n",
    "    full_table_id = f\"{hyros_save.gcp_project_id}.{dataset_id}.{resume_table}\"\n",
    "\n",
    "    def get_resume_state():\n",
    "        try:\n",
    "            query = f\"SELECT page_id FROM `{full_table_id}` LIMIT 1\"\n",
    "            result = bq_client.query(query).result()\n",
    "            row = next(result, None)\n",
    "            if row:\n",
    "                return int(row.page_id)\n",
    "        except Exception as e:\n",
    "            print(f\"Couldn't read resume state from BQ: {e}\")\n",
    "        return 1  # default page_id\n",
    "\n",
    "    def save_resume_state(page_id):\n",
    "        df = pd.DataFrame([{\"page_id\": int(page_id)}])\n",
    "        hyros_save.start_transfer_df(\n",
    "            bq_client=bq_client,\n",
    "            df=df,\n",
    "            destination_table=resume_table,\n",
    "            write_options='overwrite'\n",
    "        )\n",
    "        print(f\"Saved resume state: page_id={page_id}\")\n",
    "\n",
    "    if use_date_and_pagination:\n",
    "        if not start_date or not end_date:\n",
    "            raise ValueError(\"Both 'start_date' and 'end_date' are required when using pagination.\")\n",
    "\n",
    "        # Convert to full-day datetime strings\n",
    "        start_dt = datetime.fromisoformat(start_date).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "        end_dt = datetime.fromisoformat(end_date).replace(hour=23, minute=59, second=59, microsecond=0)\n",
    "        fromDate = start_dt.isoformat()\n",
    "        toDate = end_dt.isoformat()\n",
    "\n",
    "        page_id = get_resume_state()\n",
    "        page_counter = 0\n",
    "        collected_pages = []\n",
    "\n",
    "        while True:\n",
    "            url = f\"https://api.hyros.com/v1/api/v1.0/{endpoint}?fromDate={fromDate}&toDate={toDate}&pageSize=250&pageId={page_id}\"\n",
    "            print(f\"Request: {url}\")\n",
    "            request = Request(url, headers=headers)\n",
    "\n",
    "            try:\n",
    "                response_body = urlopen(request).read()\n",
    "                json_str = response_body.decode('utf-8')\n",
    "                data = json.loads(json_str)\n",
    "                page_df = pd.json_normalize(data['result'])\n",
    "\n",
    "                if page_df.empty:\n",
    "                    print(f\"No data for date range {start_date} to {end_date}, page {page_id}\")\n",
    "                    break\n",
    "\n",
    "                collected_pages.append(page_df)\n",
    "                page_counter += 1\n",
    "                next_page = data.get('nextPageId')\n",
    "\n",
    "                # Process & save every 10 pages\n",
    "                if page_counter % 10 == 0:\n",
    "                    combined_df = pd.concat(collected_pages, ignore_index=True)\n",
    "                    _process_and_save_df(combined_df, destination_table, start_date, page_id)\n",
    "                    collected_pages = []\n",
    "                    save_resume_state(next_page)\n",
    "\n",
    "                # If no more pages, process remaining data and save resume\n",
    "                if not next_page:\n",
    "                    if collected_pages:\n",
    "                        combined_df = pd.concat(collected_pages, ignore_index=True)\n",
    "                        _process_and_save_df(combined_df, destination_table, start_date, page_id)\n",
    "                    save_resume_state(1)  # reset tracker\n",
    "                    break\n",
    "\n",
    "                page_id = next_page\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error on page {page_id}: {e}\")\n",
    "                return\n",
    "\n",
    "    else:\n",
    "        print(f\"Fetching non-date endpoint: {endpoint}\")\n",
    "        url = f\"https://api.hyros.com/v1/api/v1.0/{endpoint}\"\n",
    "        request = Request(url, headers=headers)\n",
    "\n",
    "        try:\n",
    "            response_body = urlopen(request).read()\n",
    "            json_str = response_body.decode('utf-8')\n",
    "            data = json.loads(json_str)\n",
    "            df = pd.json_normalize(data['result'])\n",
    "\n",
    "            if df.empty:\n",
    "                print(\"No data returned.\")\n",
    "            else:\n",
    "                _process_and_save_df(df, destination_table, \"n/a\", \"n/a\")\n",
    "        except Exception as e:\n",
    "            print(f\"API call failed: {e}\")"
   ],
   "id": "2e9d5a1b9c95b9f0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T15:39:53.343934Z",
     "start_time": "2025-06-16T15:39:50.327761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query = \"\"\"\n",
    "    SELECT DISTINCT lead.firstSource.adSource.adSourceId AS adSourceId\n",
    "    FROM `arboreal-cat-451816-n0.hyros.user_journey`\n",
    "    WHERE lead.firstSource.adSource.adSourceId IS NOT NULL\n",
    "\"\"\"\n",
    "ad_source_ids_df = bq_client.query(query).to_dataframe()\n",
    "ad_source_ids = ad_source_ids_df['adSourceId'].dropna().astype(str).tolist()\n"
   ],
   "id": "e28c4050fb98161a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shami/personal_projects/vexis_authLive/.venv/lib/python3.9/site-packages/google/cloud/bigquery/table.py:1820: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T15:44:18.203889Z",
     "start_time": "2025-06-16T15:44:18.190226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ad_source_ids_param = \",\".join(f'\"{x}\"' for x in ad_source_ids[0:9])\n",
    "include_organic = \"true\"\n",
    "include_disregarded = \"false\"\n",
    "integration_type = \"ALL\"\n",
    "page_size = 250\n",
    "page_id = 1"
   ],
   "id": "75341cce59c9f3ae",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T15:44:19.845597Z",
     "start_time": "2025-06-16T15:44:18.693686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "endpoint = f\"\"\"sources?adSourceIds={ad_source_ids_param}&includeOrganic={include_organic}&includeDisregarded={include_disregarded}&integrationType={integration_type}&pageSize={page_size}&pageId={page_id}\"\"\"\n",
    "\n",
    "# Call the function (non-date based)\n",
    "fetch_and_store_hyros_data(\n",
    "    endpoint=endpoint,\n",
    "    destination_table='sources',\n",
    "    use_date_and_pagination=False  # because this endpoint is not date-based\n",
    ")"
   ],
   "id": "cc45694afe31c0c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching non-date endpoint: sources?adSourceIds=\"120228331837710196\",\"120229270339050196\",\"120229964872380242\",\"120228028354760283\",\"120227927598160283\",\"120227767691450283\",\"120229068614010196\",\"120229068741670196\",\"120225673914670578\"&includeOrganic=true&includeDisregarded=false&integrationType=ALL&pageSize=250&pageId=1\n",
      "API call failed: HTTP Error 400: \n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2686f43d3f63f0b6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
